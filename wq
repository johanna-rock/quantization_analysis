#!/usr/bin/env python3
from __future__ import annotations

import argparse
import csv
import json
import os
import re
import sys
import time
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
import secrets

import numpy as np
from tqdm import tqdm

from compression_algorithms import create_algorithm
from compression_algorithms.cache import CacheContext
from compression_algorithms.config import load_compression_config
from compression_algorithms.metrics import pearson_corr
from compression_algorithms.quantizer import Quantizer
from compression_algorithms.tile_utils import MIXED_TILE_BYTES_PER_ELEM, MIXED_TILE_FORMATS
from hf_model_utils import (
    _safe_repo_revision_key,
    _safe_tensor_key,
    build_model_index,
    fp32_tensor_cache_dir,
    load_tensor_fp32,
    resolve_format_list,
    resolve_selected_tensors,
)
from quantization_formats import SUPPORTED_FORMATS


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        prog="wq",
        description="Weight quantization analyzer for Hugging Face checkpoints.",
    )
    parser.add_argument("repo_or_url", help="Hugging Face model repo/URL.")
    parser.add_argument(
        "filter_query",
        nargs="*",
        help="Optional filter: substring, or dotted torch-style prefix path.",
    )
    parser.add_argument("--revision", default="main", help="Hugging Face revision (default: main).")
    parser.add_argument(
        "--cache-dir",
        default="data/hf-cache",
        help="Shared local cache for downloaded/dequantized tensors (default: data/hf-cache).",
    )
    parser.add_argument(
        "--limit", type=int, default=None, help="Optional max matched tensors."
    )
    parser.add_argument(
        "--backend",
        choices=["emulation", "ttnn"],
        default="emulation",
        help="Quantization backend for BFP formats (default: emulation).",
    )
    parser.add_argument(
        "--compression-config",
        type=str,
        default=None,
        help="Path to a JSON compression config file (default: none).",
    )
    parser.add_argument(
        "--recompute",
        action="store_true",
        help="Recompute and overwrite cached quantized tensors.",
    )
    parser.add_argument(
        "--summary",
        action="store_true",
        help="Print the aggregate summary (default: off).",
    )
    return parser.parse_args()


def _tensor_meta_str(x: np.ndarray) -> str:
    x = np.asarray(x, dtype=np.float32)
    return f"shape={tuple(x.shape)} min={np.min(x):.3e} mean={np.mean(x):.3e} max={np.max(x):.3e}"


COLOR_ENABLED = sys.stdout.isatty() and os.getenv("TERM", "") != "dumb" and not os.getenv("NO_COLOR")
COLORS = {
    "reset": "\033[0m",
    "title": "\033[1;37m",
    "muted": "\033[90m",
    "good": "\033[92m",
    "mid": "\033[93m",
    "bad": "\033[91m",
    "cyan": "\033[96m",
}


def paint(text: str, color: str) -> str:
    if not COLOR_ENABLED:
        return text
    return f"{COLORS[color]}{text}{COLORS['reset']}"


ANSI_RE = re.compile(r"\x1b\[[0-9;]*m")


def strip_ansi(text: str) -> str:
    return ANSI_RE.sub("", text)


def _slug(s: str) -> str:
    return re.sub(r"[^a-zA-Z0-9._-]+", "_", s).strip("_") or "tensor"


def color_pcc(v: float) -> str:
    if v >= 0.999:
        return "good"
    if v >= 0.99:
        return "mid"
    return "bad"


def pcc_plot_color(v: float) -> str:
    bucket = color_pcc(v)
    if bucket == "good":
        return "#2ca02c"
    if bucket == "mid":
        return "#ffbf00"
    return "#d62728"

FORMAT_BYTES_PER_ELEM = {
    "mxfp4": 0.5,
    "nvfp4": 0.5,
    "bf16": 2.0,
    "bfp8": 1.088,
    "bfp4": 0.50097,
    "bfp2": 0.25097,
    "fp0": 0.0,
}


def color_err(v: float) -> str:
    if v <= 1e-4:
        return "good"
    if v <= 1e-3:
        return "mid"
    return "bad"


def _write_mixed_tile_random_outputs(
    out_dir: Path,
    tensor_name: str,
    samples: list[dict],
    tile_formats: list[str],
    assignment: np.ndarray | None,
) -> None:
    if not samples:
        return

    mt_dir = out_dir / "mixed_tile_random"
    mt_dir.mkdir(parents=True, exist_ok=True)
    slug = _slug(tensor_name)

    csv_path = mt_dir / f"{slug}.csv"
    headers = ["sample_id", *[f"{fmt}_tiles" for fmt in tile_formats], "total_gb", "pcc", "mae", "atol"]
    with csv_path.open("w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(headers)
        for sample in samples:
            counts = sample.get("counts", {})
            total_gb = float(sample.get("total_bytes", 0.0)) / 1e9
            row = [
                sample.get("id"),
                *[counts.get(fmt, 0) for fmt in tile_formats],
                total_gb,
                sample.get("pcc"),
                sample.get("mae"),
                sample.get("atol"),
            ]
            writer.writerow(row)

    if assignment is not None:
        assign_path = mt_dir / f"{slug}_assignment.npy"
        np.save(assign_path, assignment.astype(np.int8))
        mapping_path = mt_dir / f"{slug}_assignment_mapping.json"
        mapping = {
            "tile_hw": 32,
            "format_to_int": {fmt: idx for idx, fmt in enumerate(MIXED_TILE_FORMATS)},
            "int_to_format": MIXED_TILE_FORMATS,
            "assignment_shape": list(assignment.shape),
        }
        with mapping_path.open("w", encoding="utf-8") as f:
            json.dump(mapping, f, indent=2)

    try:
        import matplotlib

        matplotlib.use("Agg")
        import matplotlib.pyplot as plt
    except Exception:
        return

    xs = [float(sample.get("pcc", 0.0)) for sample in samples]
    ys = [float(sample.get("total_bytes", 0.0)) / 1e9 for sample in samples]
    colors = [pcc_plot_color(x) for x in xs]

    fig, ax = plt.subplots(figsize=(6.5, 4.5))
    ax.scatter(xs, ys, c=colors, s=28, alpha=0.9)
    for sample, x, y in zip(samples, xs, ys):
        ax.annotate(str(sample.get("id")), (x, y), textcoords="offset points", xytext=(4, 4), fontsize=7)
    ax.set_xlabel("PCC")
    ax.set_ylabel("Total size (GB)")
    ax.set_title("Mixed-tile random samples")
    ax.grid(True, alpha=0.3)
    fig.tight_layout()
    fig.savefig(mt_dir / f"{slug}.png", dpi=160)
    plt.close(fig)


def _write_tile_assignment_plot(
    out_dir: Path,
    tensor_name: str,
    assignment: np.ndarray,
) -> None:
    try:
        import matplotlib

        matplotlib.use("Agg")
        import matplotlib.pyplot as plt
    except Exception:
        return

    if assignment.size == 0:
        return

    fmt_bytes = {fmt: MIXED_TILE_BYTES_PER_ELEM[fmt] for fmt in MIXED_TILE_FORMATS}
    sorted_fmts = sorted(MIXED_TILE_FORMATS, key=lambda f: fmt_bytes[f], reverse=True)
    cmap = plt.get_cmap("Blues")
    color_steps = np.linspace(0.95, 0.15, num=len(sorted_fmts))
    fmt_to_color = {fmt: cmap(step) for fmt, step in zip(sorted_fmts, color_steps)}
    idx_to_color = [fmt_to_color[fmt] for fmt in MIXED_TILE_FORMATS]

    assignment_idx = np.asarray(assignment, dtype=np.int16)
    mask = assignment_idx < 0
    assignment_idx = np.where(mask, 0, assignment_idx)

    h, w = assignment_idx.shape
    cell_size = 0.4
    fig_w = max(6.0, min(18.0, w * cell_size))
    fig_h = max(6.0, min(18.0, h * cell_size))
    fig, ax = plt.subplots(figsize=(fig_w, fig_h))
    data = assignment_idx.astype(np.int16)
    cmap_listed = matplotlib.colors.ListedColormap(idx_to_color)
    cmap_listed.set_bad("gray")
    img = np.ma.array(data, mask=mask)
    ax.imshow(img, cmap=cmap_listed, vmin=-0.5, vmax=len(MIXED_TILE_FORMATS) - 0.5, interpolation="nearest")

    x_step = 1 if w <= 64 else max(1, w // 32)
    y_step = 1 if h <= 64 else max(1, h // 32)
    ax.set_xticks(np.arange(0, w, x_step))
    ax.set_yticks(np.arange(0, h, y_step))
    ax.set_xticklabels([str(i) for i in range(0, w, x_step)], fontsize=7)
    ax.set_yticklabels([str(i) for i in range(0, h, y_step)], fontsize=7)
    ax.set_xlabel("Tile X")
    ax.set_ylabel("Tile Y")

    ax.set_xticks(np.arange(-0.5, w, 1), minor=True)
    ax.set_yticks(np.arange(-0.5, h, 1), minor=True)
    ax.grid(which="minor", color="white", linewidth=0.5, alpha=0.6)
    ax.tick_params(which="minor", bottom=False, left=False)
    ax.set_title("Tile format assignment")

    from matplotlib.patches import Patch

    legend_handles = [Patch(color=fmt_to_color[fmt], label=fmt.upper()) for fmt in sorted_fmts]
    ax.legend(handles=legend_handles, title="Data format", loc="upper right", fontsize=8)
    fig.tight_layout()

    out_dir.mkdir(parents=True, exist_ok=True)
    slug = _slug(tensor_name)
    fig.savefig(out_dir / f"{slug}_assignment.png", dpi=160)
    plt.close(fig)


def _mixed_tile_dir(out_dir: Path, algo_dir: str, tensor_name: str) -> Path:
    slug = _slug(tensor_name)
    return out_dir / algo_dir / slug


def _mixed_tile_threshold_dir(out_dir: Path, tensor_name: str) -> Path:
    return _mixed_tile_dir(out_dir, "mixed_tile_threshold", tensor_name)


def _write_mixed_tile_assignment_outputs(
    out_dir: Path,
    tensor_name: str,
    assignment: np.ndarray | None,
    algo_dir: str,
) -> None:
    if assignment is None:
        return
    mt_dir = _mixed_tile_dir(out_dir, algo_dir, tensor_name)
    mt_dir.mkdir(parents=True, exist_ok=True)
    assign_path = mt_dir / "assignment.npy"
    np.save(assign_path, assignment.astype(np.int8))
    mapping_path = mt_dir / "assignment_mapping.json"
    mapping = {
        "tile_hw": 32,
        "format_to_int": {fmt: idx for idx, fmt in enumerate(MIXED_TILE_FORMATS)},
        "int_to_format": MIXED_TILE_FORMATS,
        "assignment_shape": list(assignment.shape),
    }
    with mapping_path.open("w", encoding="utf-8") as f:
        json.dump(mapping, f, indent=2)
    _write_tile_assignment_plot(mt_dir, tensor_name, assignment)


def _write_mixed_tile_threshold_outputs(
    out_dir: Path,
    tensor_name: str,
    assignment: np.ndarray | None,
) -> None:
    _write_mixed_tile_assignment_outputs(out_dir, tensor_name, assignment, "mixed_tile_threshold")


def _write_mixed_tile_greedy_outputs(
    out_dir: Path,
    tensor_name: str,
    assignment: np.ndarray | None,
) -> None:
    _write_mixed_tile_assignment_outputs(out_dir, tensor_name, assignment, "mixed_tile_greedy")


def _write_mixed_tile_size_plot(
    out_dir: Path,
    tensor_name: str,
    metric_name: str,
    points: list[dict],
    formats: list[str],
    algo_dir: str,
) -> None:
    if not points:
        return
    try:
        import matplotlib

        matplotlib.use("Agg")
        import matplotlib.pyplot as plt
    except Exception:
        return

    if metric_name == "pcc":
        best_pcc = max(p["metric"] for p in points)
        cutoff = 0.5 * best_pcc
        points = [p for p in points if p["metric"] >= cutoff]
        if not points:
            return

    max_bytes = max(p["bytes"] for p in points)
    if max_bytes >= 1e9:
        scale = 1e9
        unit = "GB"
    elif max_bytes >= 1e6:
        scale = 1e6
        unit = "MB"
    else:
        scale = 1e3
        unit = "KB"

    xs = [p["bytes"] / scale for p in points]
    ys = [p["metric"] for p in points]
    labels = [p["label"] for p in points]
    colors = ["#1f77b4" if p.get("kind") == "baseline" else "#d62728" for p in points]
    markers = ["o" if p.get("kind") == "baseline" else "X" for p in points]

    fig, ax = plt.subplots(figsize=(6.0, 4.5))
    for x, y, label, color, marker, point in zip(xs, ys, labels, colors, markers, points):
        ax.scatter([x], [y], color=color, marker=marker, s=50)
        size_mb = x * (scale / 1e6)
        tile_parts = []
        for fmt in formats:
            count = point.get(f"{fmt}_tiles")
            if count is not None:
                tile_parts.append(f"{fmt}:{count}")
        tile_text = f" [{' '.join(tile_parts)}]" if tile_parts else ""
        ax.annotate(
            f"{label} ({y:.3g}, {size_mb:.2f}MB){tile_text}",
            (x, y),
            textcoords="offset points",
            xytext=(4, 4),
            fontsize=6,
        )

    ax.set_xlabel(f"Size ({unit})")
    ax.set_ylabel(metric_name.upper())
    ax.set_title("Size vs accuracy")
    ax.grid(True, alpha=0.3)
    if formats:
        from matplotlib.lines import Line2D

        legend_elements = [
            Line2D([0], [0], marker="o", color="w", label="Baseline", markerfacecolor="#1f77b4", markersize=7),
            Line2D([0], [0], marker="X", color="w", label="Mixed", markerfacecolor="#d62728", markersize=7),
            Line2D([0], [0], color="w", label="Annot: label (metric, size) [fmt:tiles]"),
        ]
        ax.legend(handles=legend_elements, loc="best", fontsize=8)
    fig.tight_layout()

    mt_dir = _mixed_tile_dir(out_dir, algo_dir, tensor_name)
    mt_dir.mkdir(parents=True, exist_ok=True)
    fig.savefig(mt_dir / "size_vs_accuracy.png", dpi=160)
    plt.close(fig)


def _write_mixed_tile_threshold_size_plot(
    out_dir: Path,
    tensor_name: str,
    metric_name: str,
    points: list[dict],
    formats: list[str],
) -> None:
    _write_mixed_tile_size_plot(out_dir, tensor_name, metric_name, points, formats, "mixed_tile_threshold")


def _write_mixed_tile_greedy_size_plot(
    out_dir: Path,
    tensor_name: str,
    metric_name: str,
    points: list[dict],
    formats: list[str],
) -> None:
    _write_mixed_tile_size_plot(out_dir, tensor_name, metric_name, points, formats, "mixed_tile_greedy")


def _emit_mixed_tile_size_plot(
    out_dir: Path,
    tensor_name: str,
    metric_name: str,
    rows_by_comp: dict[str, list[Row]],
    algo_name: str,
) -> None:
    if algo_name not in rows_by_comp:
        return
    points: list[dict] = []
    total_tiles = None
    for r in rows_by_comp.get(algo_name, []):
        if r.tile_counts:
            total_tiles = sum(r.tile_counts.values())
            break
    for r in rows_by_comp.get("none", []):
        metric_value = r.pcc if metric_name == "pcc" else (r.mae if metric_name == "mae" else r.atol)
        baseline_counts = {fmt: 0 for fmt in MIXED_TILE_FORMATS}
        fmt_key = r.fmt.lower()
        if total_tiles is not None and fmt_key in baseline_counts:
            baseline_counts[fmt_key] = total_tiles
        points.append(
            {
                "label": r.fmt.upper(),
                "bytes": r.gb * 1e9,
                "metric": metric_value,
                "kind": "baseline",
                **{f"{fmt}_tiles": baseline_counts.get(fmt, 0) for fmt in MIXED_TILE_FORMATS},
            }
        )
    for r in rows_by_comp.get(algo_name, []):
        metric_value = r.pcc if metric_name == "pcc" else (r.mae if metric_name == "mae" else r.atol)
        mixed_counts = {fmt: 0 for fmt in MIXED_TILE_FORMATS}
        if r.tile_counts:
            for fmt in MIXED_TILE_FORMATS:
                mixed_counts[fmt] = r.tile_counts.get(fmt, 0)
        points.append(
            {
                "label": "MIXED",
                "bytes": r.gb * 1e9,
                "metric": metric_value,
                "kind": "mixed",
                **{f"{fmt}_tiles": mixed_counts.get(fmt, 0) for fmt in MIXED_TILE_FORMATS},
            }
        )
    if algo_name == "mixed-tile-greedy":
        _write_mixed_tile_greedy_size_plot(out_dir, tensor_name, metric_name, points, MIXED_TILE_FORMATS)
    else:
        _write_mixed_tile_threshold_size_plot(out_dir, tensor_name, metric_name, points, MIXED_TILE_FORMATS)


@dataclass
class Row:
    fmt: str
    compression: str
    pcc: float
    mae: float
    atol: float
    time_s: float
    gb: float
    tile_counts: dict[str, int] | None = None
    tile_bytes: float | None = None


def _import_ttnn_quiet():
    os.environ.setdefault("LOGURU_LEVEL", "ERROR")
    os.environ.setdefault("TTNN_LOG_LEVEL", "ERROR")
    os.environ.setdefault("TT_METAL_LOGGER_LEVEL", "ERROR")
    try:
        import ttnn  # pylint: disable=import-outside-toplevel
    except ModuleNotFoundError as exc:
        raise RuntimeError("TTNN backend requires `ttnn` in the active Python environment.") from exc
    return ttnn


def _build_hierarchy(tensor_names: list[str]) -> dict:
    root: dict = {}
    for name in sorted(tensor_names):
        node = root
        for part in name.split("."):
            node = node.setdefault(part, {})
    return root


def _count_leaves(node: dict) -> int:
    if not node:
        return 1
    return sum(_count_leaves(child) for child in node.values())


def _render_hierarchy_lines(node: dict, prefix: str = "") -> list[str]:
    lines: list[str] = []
    items = sorted(node.items(), key=lambda kv: kv[0])
    for i, (name, child) in enumerate(items):
        is_last = i == len(items) - 1
        branch = "└── " if is_last else "├── "
        count = _count_leaves(child)
        label = f"{name} {paint(f'({count})', 'muted') if count > 1 else ''}".rstrip()
        lines.append(f"{prefix}{branch}{label}")
        if child:
            ext = "    " if is_last else "│   "
            lines.extend(_render_hierarchy_lines(child, prefix + ext))
    return lines


def _print_hierarchy(tensor_names: list[str]) -> None:
    tree = _build_hierarchy(tensor_names)
    print(paint("Hierarchy", "title"))
    for line in _render_hierarchy_lines(tree):
        print(f"  {paint(line, 'muted')}")
    print()


def run() -> int:
    args = parse_args()
    run_tag = datetime.now().strftime("%Y%m%d-%H%M%S")

    config = load_compression_config(args.compression_config)
    algo_params = dict(config.params)
    seed_source = None
    used_seed = None
    if config.seed is not None:
        config_seed = int(config.seed)
        if config_seed == 0:
            used_seed = secrets.randbits(31)
            seed_source = "random"
        else:
            used_seed = config_seed
            seed_source = "config"
    elif config.random_seed:
        used_seed = secrets.randbits(31)
        seed_source = "random"

    if used_seed is not None:
        algo_params["seed"] = used_seed
    elif "seed" in algo_params:
        param_seed = algo_params["seed"]
        try:
            param_seed_int = int(param_seed)
        except (TypeError, ValueError):
            used_seed = param_seed
            seed_source = "params"
        else:
            if param_seed_int == 0:
                used_seed = secrets.randbits(31)
                algo_params["seed"] = used_seed
                seed_source = "random"
            else:
                used_seed = param_seed_int
                algo_params["seed"] = used_seed
                seed_source = "params"

    selected_algo = create_algorithm(config.algorithm, algo_params)
    baseline = create_algorithm("none", {})
    algorithms = [baseline] if selected_algo.name == "none" else [baseline, selected_algo]

    filter_query = " ".join(args.filter_query).strip() or None
    formats = resolve_format_list(config.quantization_formats, SUPPORTED_FORMATS)

    index = build_model_index(repo_or_url=args.repo_or_url, revision=args.revision, cache_dir=args.cache_dir)
    tensor_names = resolve_selected_tensors(index, filter_query)
    if args.limit is not None:
        tensor_names = tensor_names[: max(0, args.limit)]
    if not tensor_names:
        print("No tensors matched.", file=sys.stderr)
        return 1

    ttnn = None
    if args.backend == "ttnn":
        try:
            ttnn = _import_ttnn_quiet()
        except Exception as exc:
            print(f"error: {exc}", file=sys.stderr)
            return 1

    quantizer = Quantizer(backend=args.backend, ttnn=ttnn)

    compression_names = [algo.name for algo in algorithms]
    comp_w = max(len("COMP"), max((len(name) for name in compression_names), default=0))
    results_dir = None
    table_lines: list[str] = []
    print(
        f"{paint(index.repo_id, 'title')} {paint('@', 'muted')}{paint(index.revision, 'cyan')} "
        f"{paint('-', 'muted')} {paint(str(len(tensor_names)), 'title')} {paint('tensors', 'muted')}"
    )
    print(f"{paint('formats:', 'muted')} {', '.join(formats)}")
    print(f"{paint('compression:', 'muted')} {', '.join(compression_names)}")
    print(f"{paint('backend:', 'muted')} {args.backend}")
    if args.compression_config:
        print(f"{paint('config:', 'muted')} {args.compression_config}")
    print()
    _print_hierarchy(tensor_names)

    safe_model = index.repo_id.replace("/", "__")
    results_dir = Path("results") / safe_model / selected_algo.name / run_tag
    results_dir.mkdir(parents=True, exist_ok=True)
    used_params = dict(algo_params)
    if used_seed is not None and "seed" in used_params:
        used_params.pop("seed", None)

    used_config = {
        "algorithm": config.algorithm,
        "quantization_formats": formats,
        "params": used_params,
    }
    if used_seed is not None:
        used_config["seed"] = used_seed
        if seed_source:
            used_config["seed_source"] = seed_source

    with (results_dir / "compression_config.used.json").open("w", encoding="utf-8") as f:
        json.dump(used_config, f, indent=2)

    processed_root = Path("data/processed") / _safe_repo_revision_key(index.repo_id, index.revision)
    aggregate: dict[tuple[str, str], list[Row]] = {}

    total_evals = len(tensor_names) * sum(algo.expected_evals(formats) for algo in algorithms)
    pbar = tqdm(total=total_evals, desc="Evaluating", unit="eval")

    for tensor_name in tensor_names:
        cache_file = fp32_tensor_cache_dir(index) / f"{_safe_tensor_key(tensor_name)}.npy"
        if cache_file.exists():
            print(f"{paint('cache:', 'muted')} fp32 hit ({cache_file})")
        else:
            print(f"{paint('cache:', 'muted')} fp32 miss -> loading from HF cache/download")
        x = load_tensor_fp32(index, tensor_name)
        xf = np.asarray(x, dtype=np.float32)
        title_line = paint(tensor_name, "title")
        print(title_line)
        table_lines.append(strip_ansi(title_line))
        meta_line = f"  {paint(_tensor_meta_str(xf), 'muted')}"
        print(meta_line)
        table_lines.append(strip_ansi(meta_line))

        cache_ctx = CacheContext(
            root=processed_root,
            tensor_name=tensor_name,
            backend=args.backend,
            recompute=args.recompute,
            run_tag=run_tag,
        )

        rows_by_comp: dict[str, list[Row]] = {}
        for algo in algorithms:
            t0 = time.perf_counter()
            results = algo.run(xf=xf, formats=formats, quantizer=quantizer, cache=cache_ctx)
            elapsed = time.perf_counter() - t0
            for res in results:
                diff = np.abs(xf - res.y)
                mae = float(np.mean(diff))
                atol = float(np.max(diff))
                pcc = pearson_corr(xf, res.y)
                fmt_l = res.fmt.lower()
                bytes_per_elem = FORMAT_BYTES_PER_ELEM.get(fmt_l)
                if res.tile_bytes is not None:
                    gb = float(res.tile_bytes) / 1e9
                elif bytes_per_elem is not None:
                    gb = float(xf.size) * float(bytes_per_elem) / 1e9
                else:
                    gb = 0.0
                row = Row(
                    fmt=res.fmt,
                    compression=res.compression,
                    pcc=pcc,
                    mae=mae,
                    atol=atol,
                    time_s=elapsed,
                    gb=gb,
                    tile_counts=res.tile_counts,
                    tile_bytes=res.tile_bytes,
                )
                rows_by_comp.setdefault(res.compression, []).append(row)
                aggregate.setdefault((res.compression, res.fmt), []).append(row)
                pbar.update(1)

                if (
                    res.compression == "mixed-tile-random"
                    and res.meta
                    and results_dir is not None
                ):
                    samples = res.meta.get("samples")
                    tile_formats = res.meta.get("tile_formats", [])
                    assignment = res.meta.get("assignment")
                    if isinstance(samples, list) and tile_formats:
                        _write_mixed_tile_random_outputs(
                            results_dir, tensor_name, samples, tile_formats, assignment
                        )
                if (
                    res.compression == "mixed-tile-threshold"
                    and res.meta
                    and results_dir is not None
                ):
                    assignment = res.meta.get("assignment")
                    if isinstance(assignment, np.ndarray):
                        _write_mixed_tile_threshold_outputs(
                            results_dir, tensor_name, assignment
                        )
                if (
                    res.compression == "mixed-tile-greedy"
                    and res.meta
                    and results_dir is not None
                ):
                    assignment = res.meta.get("assignment")
                    if isinstance(assignment, np.ndarray):
                        _write_mixed_tile_greedy_outputs(
                            results_dir, tensor_name, assignment
                        )

        if (
            results_dir is not None
            and selected_algo.name in {"mixed-tile-threshold", "mixed-tile-greedy"}
        ):
            metric_name = algo_params.get("metric", "pcc")
            _emit_mixed_tile_size_plot(
                results_dir, tensor_name, metric_name, rows_by_comp, selected_algo.name
            )

        for comp in compression_names:
            rows = rows_by_comp.get(comp, [])
            if not rows:
                continue
            fmt_w = max(len(r.fmt) for r in rows)
            if comp in {"mixed-tile-greedy", "mixed-tile-random", "mixed-tile-threshold"}:
                count_widths = {k: len(k.upper()) for k in MIXED_TILE_FORMATS}
                bytes_w = len("BYTES")
                time_w = len("TIME(s)")
                gb_w = len("GB")
                pcc_w = len("PCC")
                mae_w = len("MAE")
                atol_w = len("ATOL")
                for r in rows:
                    counts = r.tile_counts or {}
                    for k in MIXED_TILE_FORMATS:
                        count_widths[k] = max(count_widths[k], len(str(counts.get(k, 0))))
                    if r.tile_bytes is not None:
                        bytes_w = max(bytes_w, len(f"{r.tile_bytes:,.0f}"))
                    time_w = max(time_w, len(f"{r.time_s:.3f}"))
                    gb_w = max(gb_w, len(f"{r.gb:.3f}"))
                    pcc_w = max(pcc_w, len(f"{r.pcc: .5f}"))
                    mae_w = max(mae_w, len(f"{r.mae:.3e}"))
                    atol_w = max(atol_w, len(f"{r.atol:.3e}"))
                count_hdr = "  ".join(k.upper().rjust(count_widths[k]) for k in MIXED_TILE_FORMATS)
                header = (
                    f"  {paint('COMP'.ljust(comp_w), 'muted')}  {paint('FORMAT'.ljust(fmt_w), 'muted')}  "
                    f"{paint('PCC'.rjust(pcc_w), 'muted')}  "
                    f"{paint('MAE'.rjust(mae_w), 'muted')}  "
                    f"{paint('ATOL'.rjust(atol_w), 'muted')}  "
                    f"{paint('TIME(s)'.rjust(time_w), 'muted')}  "
                    f"{paint('GB'.rjust(gb_w), 'muted')}  "
                    f"{paint(count_hdr, 'muted')}  {paint('BYTES'.rjust(bytes_w), 'muted')}"
                )
                print(header)
                table_lines.append(strip_ansi(header))
                for r in rows:
                    pcc_txt = f"{r.pcc: .5f}".rjust(pcc_w)
                    mae_txt = f"{r.mae:.3e}".rjust(mae_w)
                    atol_txt = f"{r.atol:.3e}".rjust(atol_w)
                    time_txt = f"{r.time_s:.3f}".rjust(time_w)
                    gb_txt = f"{r.gb:.3f}".rjust(gb_w)
                    counts = r.tile_counts or {}
                    counts_txt = "  ".join(str(counts.get(k, 0)).rjust(count_widths[k]) for k in MIXED_TILE_FORMATS)
                    bytes_txt = f"{(r.tile_bytes or 0.0):,.0f}".rjust(bytes_w)
                    line = (
                        f"  {r.compression.ljust(comp_w)}  {r.fmt.ljust(fmt_w)}  "
                        f"{paint(pcc_txt, color_pcc(r.pcc))}  "
                        f"{paint(mae_txt, color_err(r.mae))}  "
                        f"{paint(atol_txt, color_err(r.atol))}  "
                        f"{time_txt}  "
                        f"{gb_txt}  "
                        f"{counts_txt}  {bytes_txt}"
                    )
                    print(line)
                    table_lines.append(strip_ansi(line))
            else:
                time_w = len("TIME(s)")
                gb_w = len("GB")
                pcc_w = len("PCC")
                mae_w = len("MAE")
                atol_w = len("ATOL")
                for r in rows:
                    time_w = max(time_w, len(f"{r.time_s:.3f}"))
                    gb_w = max(gb_w, len(f"{r.gb:.3f}"))
                    pcc_w = max(pcc_w, len(f"{r.pcc: .5f}"))
                    mae_w = max(mae_w, len(f"{r.mae:.3e}"))
                    atol_w = max(atol_w, len(f"{r.atol:.3e}"))
                header = (
                    f"  {paint('COMP'.ljust(comp_w), 'muted')}  {paint('FORMAT'.ljust(fmt_w), 'muted')}  "
                    f"{paint('PCC'.rjust(pcc_w), 'muted')}  "
                    f"{paint('MAE'.rjust(mae_w), 'muted')}  "
                    f"{paint('ATOL'.rjust(atol_w), 'muted')}  "
                    f"{paint('TIME(s)'.rjust(time_w), 'muted')}  "
                    f"{paint('GB'.rjust(gb_w), 'muted')}"
                )
                print(header)
                table_lines.append(strip_ansi(header))
                for r in rows:
                    pcc_txt = f"{r.pcc: .5f}".rjust(pcc_w)
                    mae_txt = f"{r.mae:.3e}".rjust(mae_w)
                    atol_txt = f"{r.atol:.3e}".rjust(atol_w)
                    time_txt = f"{r.time_s:.3f}".rjust(time_w)
                    gb_txt = f"{r.gb:.3f}".rjust(gb_w)
                    line = (
                        f"  {r.compression.ljust(comp_w)}  {r.fmt.ljust(fmt_w)}  "
                        f"{paint(pcc_txt, color_pcc(r.pcc))}  "
                        f"{paint(mae_txt, color_err(r.mae))}  "
                        f"{paint(atol_txt, color_err(r.atol))}  "
                        f"{time_txt}  "
                        f"{gb_txt}"
                    )
                    print(line)
                    table_lines.append(strip_ansi(line))
            print()
            table_lines.append("")

    pbar.close()
    if args.summary:
        print(paint("Summary (mean across matched tensors)", "title"))
        table_lines.append("Summary (mean across matched tensors)")
        for comp in compression_names:
            if comp in {"mixed-tile-greedy", "mixed-tile-random", "mixed-tile-threshold"}:
                fmt_list = ["MIXED"]
            else:
                fmt_list = [fmt.upper() for fmt in formats]
            for fmt in fmt_list:
                rows = aggregate.get((comp, fmt), [])
                if not rows:
                    continue
                pcc = float(np.mean([r.pcc for r in rows]))
                mae = float(np.mean([r.mae for r in rows]))
                atol = float(np.mean([r.atol for r in rows]))
                bytes_vals = [r.tile_bytes for r in rows if r.tile_bytes is not None]
                bytes_txt = ""
                if bytes_vals:
                    bytes_mean = float(np.mean(bytes_vals))
                    bytes_txt = f"  bytes={bytes_mean:,.0f}"
                line = (
                    f"  {comp.ljust(comp_w)} {fmt:>5}  "
                    f"pcc={paint(f'{pcc: .5f}', color_pcc(pcc))}  "
                    f"mae={paint(f'{mae:.3e}', color_err(mae))}  "
                    f"atol={paint(f'{atol:.3e}', color_err(atol))}"
                    f"{bytes_txt}"
                )
                print(line)
                table_lines.append(strip_ansi(line))

    if results_dir is not None and table_lines:
        (results_dir / "table.txt").write_text("\n".join(table_lines) + "\n", encoding="utf-8")

    return 0


if __name__ == "__main__":
    raise SystemExit(run())
